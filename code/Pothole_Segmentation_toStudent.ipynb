{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸš€ **Pothole Segmentation with YOLOv12 (Small Model)**  \n",
        "\n",
        "## By Kao Panboonyuen\n",
        "\n",
        "### This Colab notebook will guide you through:\n",
        "\n",
        "* âœ… Preparing and loading the dataset\n",
        "* âœ… Exploring images and labels\n",
        "* âœ… Performing exploratory data analysis (EDA)\n",
        "* âœ… Training YOLOv12n (small model) for segmentation\n",
        "* âœ… Evaluating performance with accuracy, confusion matrix, precision, recall, F1-score\n",
        "* âœ… Performing inference and error analysis"
      ],
      "metadata": {
        "id": "ROwk2U1v-FLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ **Step 1: Install & Import Required Libraries**\n",
        "\n",
        "In this step, we'll install the necessary libraries for training YOLOv12. You'll need to install the YOLOv12 package, and PyTorch to enable GPU acceleration."
      ],
      "metadata": {
        "id": "uahqoWzY-J3h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzFknAsT8u3x"
      },
      "outputs": [],
      "source": [
        "!pip install torch==2.0.0+cu117 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "62NFYU7I-Lep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "1h_y6EL-Atle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ **Step 2: Download and Prepare the Dataset**\n",
        "\n",
        "Next, we will download the dataset from the link provided and extract it."
      ],
      "metadata": {
        "id": "BO68OxnD-QId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/kaopanboonyuen/OCSB-AI/blob/main/dataset/pothole_dataset.zip?raw=true -O pothole_dataset.zip\n",
        "with zipfile.ZipFile('pothole_dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')"
      ],
      "metadata": {
        "id": "hUdMQqpG-Ot7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ **Step 3: Organize Data in YOLOv12 Format**\n",
        "\n",
        "YOLOv12 requires the data to be organized in a specific format. We'll make sure that the labels and images are correctly set up."
      ],
      "metadata": {
        "id": "KqtceqVR-4TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/dataset', exist_ok=True)\n",
        "os.makedirs('/content/dataset/train', exist_ok=True)\n",
        "os.makedirs('/content/dataset/valid', exist_ok=True)\n",
        "\n",
        "shutil.move('/content/pothole_dataset/train/images', '/content/dataset/train/images')\n",
        "shutil.move('/content/pothole_dataset/train/labels', '/content/dataset/train/labels')\n",
        "shutil.move('/content/pothole_dataset/valid/images', '/content/dataset/valid/images')\n",
        "shutil.move('/content/pothole_dataset/valid/labels', '/content/dataset/valid/labels')"
      ],
      "metadata": {
        "id": "HlRm7DyP-2kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Step 4: Preview Dataset with Random Image Samples"
      ],
      "metadata": {
        "id": "PGoRPnQ5_ITk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Path to the dataset\n",
        "train_images_dir = '/content/dataset/train/images'\n",
        "train_labels_dir = '/content/dataset/train/labels'\n",
        "\n",
        "# Get a random image file\n",
        "random_image_file = random.choice(os.listdir(train_images_dir))\n",
        "random_image_path = os.path.join(train_images_dir, random_image_file)\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread(random_image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Load the corresponding label\n",
        "label_file = random_image_file.replace('.jpg', '.txt')  # Assuming .jpg format for images\n",
        "label_path = os.path.join(train_labels_dir, label_file)\n",
        "\n",
        "# Read the label file (assume it's in YOLO format or polygon format)\n",
        "with open(label_path, 'r') as file:\n",
        "    labels = file.readlines()\n",
        "\n",
        "# Plot the image and the segmentation label\n",
        "plt.imshow(image_rgb)\n",
        "\n",
        "for label in labels:\n",
        "    parts = label.strip().split()\n",
        "\n",
        "    # If the label has more than 5 values, it's likely a polygon format\n",
        "    if len(parts) > 5:\n",
        "        class_id = int(parts[0])  # Get the class ID (not used for visualization here)\n",
        "        # Parse the polygon points from the label\n",
        "        polygon_points = list(map(float, parts[1:]))  # All but the first are coordinates\n",
        "\n",
        "        # Convert the list of points to pairs of (x, y)\n",
        "        polygon_points = np.array(polygon_points).reshape(-1, 2).astype(np.int32)\n",
        "\n",
        "        # Draw the polygon on the image\n",
        "        cv2.polylines(image_rgb, [polygon_points], isClosed=True, color=(0, 255, 0), thickness=2)\n",
        "    else:\n",
        "        print(f\"Skipping label with insufficient data: {label.strip()}\")\n",
        "\n",
        "# Show the image with segmentation polygons\n",
        "plt.title('Sample Image and Segmentation Polygon')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iEwUSFG0_FwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ **Step 5: Configure the Dataset YAML File**\n",
        "\n",
        "For YOLOv12 to know how to process the dataset, we need to create a `data.yaml` configuration file. This file specifies where the dataset is located and defines the class names."
      ],
      "metadata": {
        "id": "xQfOZwGJ-9bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_yaml = \"\"\"\n",
        "train: /content/dataset/train/images\n",
        "val: /content/dataset/valid/images\n",
        "\n",
        "nc: 1\n",
        "names: ['Pothole']\n",
        "\"\"\"\n",
        "with open(\"/content/dataset/data.yaml\", \"w\") as f:\n",
        "    f.write(data_yaml)"
      ],
      "metadata": {
        "id": "yzzu0rm4-8Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ **Step 6: Load the YOLOv12 Model**\n",
        "\n",
        "Now, load the YOLOv12 small model (YOLOv12n) from the ultralytics package."
      ],
      "metadata": {
        "id": "QpJN-QOXAMDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the pretrained YOLOv12 model (if available)\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the pretrained model (adjust the URL or model name if necessary)\n",
        "# Write your code here"
      ],
      "metadata": {
        "id": "fGHuxdY2ANKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ **Step 7: Train the Model**\n",
        "\n",
        "Now that we have everything ready, we can start training the model. We will fine-tune the pre-trained YOLOv12 small model on the pothole dataset."
      ],
      "metadata": {
        "id": "4YZJGObV_Cmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here  # Change device to your GPU"
      ],
      "metadata": {
        "id": "5v5b867m_Aic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ **Step 8: Evaluate the Model**\n",
        "\n",
        "Once training is complete, evaluate the model's performance on the validation dataset."
      ],
      "metadata": {
        "id": "Hz2wRrZfA9PS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here  # Evaluate on validation set"
      ],
      "metadata": {
        "id": "6TYSSVxAAH-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ **Step 9: Inference and Error Analysis**\n",
        "\n",
        "After evaluation, it's time to run inference on some images and analyze the errors. Letâ€™s run inference on a few images and visualize the predictions."
      ],
      "metadata": {
        "id": "Yhnan06VBCYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inference on validation images\n",
        "results = model.predict('/content/dataset/valid/images', save=True)\n",
        "\n",
        "# Show inference results for a specific image\n",
        "image_path = '/content/dataset/valid/images/sample_image.jpg'\n",
        "\n",
        "# Check if the image exists\n",
        "if os.path.exists(image_path):\n",
        "    # Read the image\n",
        "    img = cv2.imread(image_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis('off')  # Hide axes\n",
        "    plt.show()\n",
        "\n",
        "    # Get the inference results for this image\n",
        "    # This will display the prediction (boxes, labels, etc.)\n",
        "    prediction_results = results.pandas().xywh  # Get results in xywh format\n",
        "    print(prediction_results)  # Print predictions\n",
        "else:\n",
        "    print(f\"Image not found at {image_path}\")"
      ],
      "metadata": {
        "id": "YsODfLXlBGwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ **Step 10: Confusion Matrix and Precision-Recall-F1 Analysis**\n",
        "\n",
        "Evaluate the predictions using metrics like Precision, Recall, and F1-Score:"
      ],
      "metadata": {
        "id": "UXdrRX3MBI1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Path to the confusion matrix image\n",
        "confusion_matrix_path = '/content/runs/detect/train/confusion_matrix.png'\n",
        "\n",
        "# Display the confusion matrix image\n",
        "# Write your code here"
      ],
      "metadata": {
        "id": "4EyqAhDEBJ3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ **Step 11: Save and Load Model**\n",
        "\n",
        "Finally, save your trained model and load it again when needed."
      ],
      "metadata": {
        "id": "jUaYNl2hBN32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "# Write your code here\n",
        "\n",
        "# Load the model\n",
        "# Write your code here"
      ],
      "metadata": {
        "id": "xmoIPlspBPhD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}